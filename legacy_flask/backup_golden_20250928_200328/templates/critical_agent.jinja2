"""
{{ class_name }} - {{ ecosystem.title() }} Ecosystem
{{ description }}
Generado automáticamente: {{ timestamp }}
Performance: {{ performance }}%
Complejidad: {{ complexity }}
"""

import json
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime
import numpy as np
from dataclasses import dataclass


@dataclass
class {{ class_name }}Config:
    tenant_id: str
    performance_threshold: float = {{ performance }}
    max_processing_time: float = 3.0
    enable_logging: bool = True


class {{ class_name }}:
    """
    {{ description }}
    
    Agente crítico de alta complejidad para el ecosistema {{ ecosystem }}.
    Implementa algoritmos avanzados de machine learning y procesamiento
    en tiempo real para evaluación crediticia empresarial.
    """
    
    def __init__(self, config: {{ class_name }}Config):
        self.config = config
        self.tenant_id = config.tenant_id
        self.performance_score = {{ performance }}
        self.ecosystem = "{{ ecosystem }}"
        self.agent_type = "{{ complexity }}"
        self.logger = self._setup_logger()
        
        # Configuración específica para agente crítico
        self.similarity_algorithms = {
            'cosine': self._cosine_similarity,
            'euclidean': self._euclidean_distance,
            'jaccard': self._jaccard_similarity,
            'hybrid': self._hybrid_algorithm
        }
        
        self.risk_thresholds = {
            'reject_auto': 0.90,
            'high_risk': 0.80,
            'medium_risk': 0.50,
            'low_risk': 0.30
        }
        
        self._initialize_critical_components()
        
    def _setup_logger(self) -> logging.Logger:
        logger = logging.getLogger(f"{{ class_name }}_{self.tenant_id}")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                f'%(asctime)s - {{ class_name }} - {self.tenant_id} - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            
        return logger
        
    def _initialize_critical_components(self):
        """Inicialización de componentes críticos para máximo rendimiento"""
        self.feature_weights = self._calculate_optimal_weights()
        self.model_ensemble = self._setup_ensemble_models()
        self.cache = {}
        
        if self.config.enable_logging:
            self.logger.info(f"{{ class_name }} inicializado para tenant {self.tenant_id}")
    
    def _calculate_optimal_weights(self) -> Dict[str, float]:
        """Calcula pesos óptimos para features según el tenant"""
        return {
            'credit_score': 0.25,
            'income_ratio': 0.20,
            'payment_history': 0.20,
            'debt_ratio': 0.15,
            'employment_stability': 0.12,
            'behavioral_score': 0.08
        }
    
    def _setup_ensemble_models(self) -> Dict[str, Any]:
        """Setup de modelos ensemble para procesamiento crítico"""
        return {
            'primary_model': self._primary_algorithm,
            'secondary_model': self._secondary_algorithm,
            'fallback_model': self._fallback_algorithm
        }
    
    def _cosine_similarity(self, vector_a: List[float], vector_b: List[float]) -> float:
        """Algoritmo de similitud coseno optimizado"""
        dot_product = np.dot(vector_a, vector_b)
        norm_a = np.linalg.norm(vector_a)
        norm_b = np.linalg.norm(vector_b)
        
        if norm_a == 0 or norm_b == 0:
            return 0.0
            
        similarity = dot_product / (norm_a * norm_b)
        return max(0.0, min(1.0, similarity))
    
    def _euclidean_distance(self, vector_a: List[float], vector_b: List[float]) -> float:
        """Distancia euclidiana normalizada"""
        distance = np.linalg.norm(np.array(vector_a) - np.array(vector_b))
        max_possible_distance = np.sqrt(len(vector_a) * 2)  # Asumiendo valores 0-1
        return 1.0 - (distance / max_possible_distance)
    
    def _jaccard_similarity(self, set_a: set, set_b: set) -> float:
        """Índice de Jaccard para características categóricas"""
        intersection = len(set_a & set_b)
        union = len(set_a | set_b)
        return intersection / union if union > 0 else 0.0
    
    def _hybrid_algorithm(self, profile_data: Dict[str, Any]) -> float:
        """Algoritmo híbrido que combina múltiples métricas"""
        numerical_features = [
            profile_data.get('credit_score', 0) / 850,
            profile_data.get('income', 0) / 100000,
            profile_data.get('debt_ratio', 0)
        ]
        
        categorical_features = set(profile_data.get('employment_type', '').split())
        historical_features = set(profile_data.get('payment_patterns', '').split())
        
        # Combinar similitudes
        cosine_sim = self._cosine_similarity(numerical_features, [0.7, 0.6, 0.3])  # Benchmark
        jaccard_sim = self._jaccard_similarity(categorical_features, {'full_time', 'stable'})
        
        # Peso ponderado
        hybrid_score = (0.6 * cosine_sim) + (0.4 * jaccard_sim)
        return hybrid_score
    
    def _primary_algorithm(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Algoritmo primario de procesamiento"""
        similarity_score = self._hybrid_algorithm(data)
        
        risk_level = self._classify_risk_level(similarity_score)
        confidence = self._calculate_confidence(similarity_score, data)
        
        return {
            'similarity_score': similarity_score,
            'risk_level': risk_level,
            'confidence': confidence,
            'algorithm_used': 'primary_hybrid'
        }
    
    def _secondary_algorithm(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Algoritmo secundario de respaldo"""
        # Implementación simplificada para casos edge
        basic_score = (
            (data.get('credit_score', 600) / 850) * 0.4 +
            (1 - data.get('debt_ratio', 0.5)) * 0.6
        )
        
        return {
            'similarity_score': basic_score,
            'risk_level': self._classify_risk_level(basic_score),
            'confidence': 0.75,
            'algorithm_used': 'secondary_basic'
        }
    
    def _fallback_algorithm(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Algoritmo de fallback para casos críticos"""
        fallback_score = 0.5  # Neutral por defecto
        
        return {
            'similarity_score': fallback_score,
            'risk_level': 'MEDIUM_RISK',
            'confidence': 0.5,
            'algorithm_used': 'fallback_neutral'
        }
    
    def _classify_risk_level(self, similarity_score: float) -> str:
        """Clasificación de nivel de riesgo basado en similitud"""
        if similarity_score >= self.risk_thresholds['reject_auto']:
            return 'REJECT_AUTO'
        elif similarity_score >= self.risk_thresholds['high_risk']:
            return 'HIGH_RISK'
        elif similarity_score >= self.risk_thresholds['medium_risk']:
            return 'MEDIUM_RISK'
        else:
            return 'LOW_RISK'
    
    def _calculate_confidence(self, similarity_score: float, data: Dict[str, Any]) -> float:
        """Calcula el nivel de confianza en la predicción"""
        base_confidence = 0.8
        
        # Ajustes basados en completitud de datos
        completeness = sum(1 for key in ['credit_score', 'income', 'debt_ratio'] 
                          if key in data and data[key] is not None) / 3
        
        confidence = base_confidence * completeness * (1 + abs(similarity_score - 0.5))
        return min(0.99, confidence)
    
    def process_evaluation(self, profile_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Procesamiento principal de evaluación crediticia
        
        Args:
            profile_data: Datos del perfil a evaluar
            
        Returns:
            Resultado completo de la evaluación
        """
        start_time = datetime.now()
        
        try:
            # Validación de datos
            if not self._validate_input(profile_data):
                raise ValueError("Datos de entrada inválidos")
            
            # Procesamiento con modelo ensemble
            result = self.model_ensemble['primary_model'](profile_data)
            
            # Validación de resultado
            if result['confidence'] < 0.6:
                self.logger.warning(f"Confianza baja: {result['confidence']}")
                result = self.model_ensemble['secondary_model'](profile_data)
            
            # Enriquecer resultado
            result.update({
                'tenant_id': self.tenant_id,
                'agent_name': '{{ class_name }}',
                'ecosystem': self.ecosystem,
                'processing_time': (datetime.now() - start_time).total_seconds(),
                'timestamp': datetime.now().isoformat(),
                'version': '1.0.0'
            })
            
            self.logger.info(f"Evaluación completada: {result['risk_level']}")
            return result
            
        except Exception as e:
            self.logger.error(f"Error en evaluación: {str(e)}")
            return self.model_ensemble['fallback_model'](profile_data)
    
    def _validate_input(self, data: Dict[str, Any]) -> bool:
        """Validación de datos de entrada"""
        required_fields = ['credit_score', 'income']
        return all(field in data and data[field] is not None for field in required_fields)
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Métricas de rendimiento del agente"""
        return {
            'agent_name': '{{ class_name }}',
            'ecosystem': self.ecosystem,
            'performance_score': self.performance_score,
            'tenant_id': self.tenant_id,
            'complexity': '{{ complexity }}',
            'algorithms_available': list(self.similarity_algorithms.keys()),
            'risk_thresholds': self.risk_thresholds
        }


def create_agent(tenant_id: str, **kwargs) -> {{ class_name }}:
    """Factory function para crear instancia del agente"""
    config = {{ class_name }}Config(tenant_id=tenant_id, **kwargs)
    return {{ class_name }}(config)


# Export para uso externo
__all__ = ['{{ class_name }}', 'create_agent', '{{ class_name }}Config']